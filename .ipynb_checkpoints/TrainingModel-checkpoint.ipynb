{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d739ca1-0d65-4d7a-b0cb-b5ff910dec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from warnings import filterwarnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization, ReLU, GlobalAveragePooling2D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b81fab3-97fb-477d-8f02-fe62a8a8b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"C:/Users/mrdee/Desktop/Dataset/Training\"\n",
    "test_path = \"C:/Users/mrdee/Desktop/Dataset/Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b712705-293c-4449-a3e3-c74bb69ceef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_dark = [\"#1F1F1F\", \"#313131\", '#636363', '#AEAEAE', '#DADADA']\n",
    "colors_red = [\"#331313\", \"#582626\", '#9E1717', '#D35151', '#E9B4B4']\n",
    "colors_green = ['#01411C','#4B6F44','#4F7942','#74C365','#D0F0C0']\n",
    "\n",
    "# sns.palplot(colors_dark)\n",
    "# sns.palplot(colors_green)\n",
    "# sns.palplot(colors_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d1adbec-c693-42f9-a0bf-a5c553bf7bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3bbdab3-cf49-4e9e-84af-7f1a03598e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 826/826 [00:17<00:00, 47.85it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 822/822 [00:17<00:00, 47.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 395/395 [00:07<00:00, 50.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 827/827 [00:18<00:00, 44.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 51.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 115/115 [00:02<00:00, 53.00it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 105/105 [00:01<00:00, 61.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 31.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2870, 150, 150, 3), (2870,), (394, 150, 150, 3), (394,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "\n",
    "image_size = 150\n",
    "for label in labels:\n",
    "    folderPath = os.path.join(train_path, label)\n",
    "    for fn in tqdm(os.listdir(folderPath)):\n",
    "        fnPath = os.path.join(folderPath, fn)\n",
    "        img = cv2.imread(fnPath)\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        X_train.append(img)\n",
    "        y_train.append(label)\n",
    "        \n",
    "for label in labels:\n",
    "    folderPath = os.path.join(test_path, label)\n",
    "    for fn in tqdm(os.listdir(folderPath)):\n",
    "        fnPath = os.path.join(folderPath, fn)\n",
    "        img = cv2.imread(fnPath)\n",
    "        img = cv2.resize(img,(image_size,image_size))\n",
    "        X_test.append(img)\n",
    "        y_test.append(label)\n",
    "        \n",
    "# Combine then split with stratify\n",
    "# X_train.extend(X_test)\n",
    "# y_train.extend(y_test)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1,random_state=42, stratify=y_train)\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a38da03-0777-478e-a27c-d3516c487bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = []\n",
    "for i in y_train:\n",
    "    y_train_new.append(labels.index(i))\n",
    "y_train = y_train_new\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "y_test_new = []\n",
    "for i in y_test:\n",
    "    y_test_new.append(labels.index(i))\n",
    "y_test = y_test_new\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a3ffdaf-bf0c-424a-859b-b2428ed5def0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2583, 150, 150, 3), (2583, 4), (287, 150, 150, 3), (287, 4))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1,random_state=42, stratify=y_train)\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7238d4e6-4e08-4d3d-8977-446d70a3717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator (\n",
    "    rotation_range = 30,\n",
    "    rescale = 1./255,\n",
    "    \n",
    "    shear_range = 0.1,\n",
    "    zoom_range = 0.2,\n",
    "    \n",
    "    horizontal_flip = True,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c1270ae-81a6-4720-a2be-4c55f1f7a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_gen = train_datagen.flow(\n",
    "    X_train, y_train, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow(\n",
    "    X_val, y_val,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4093ec14-a962-4f39-b065-6e0bed02d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, (5, 5), activation='relu', padding='same', input_shape=(image_size, image_size, 3)))\n",
    "# # model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "# # model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# # model.add(BatchNormalization())\n",
    "# # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# # model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(4, activation='softmax', name='predictions')) \n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# # model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad952241-c5d8-48bf-814e-a6b69d94807c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "effnet = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "\n",
    "model = effnet.output\n",
    "model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
    "model = tf.keras.layers.Dense(4, activation='softmax')(model)\n",
    "model = tf.keras.models.Model(inputs=effnet.input, outputs = model)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'Adam', metrics= ['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bbed98-d6b5-4f7d-97a9-bcac868402fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7655 - loss: 0.6028\n",
      "Epoch 1: val_accuracy improved from -inf to 0.79443, saving model to effnet.keras\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 5s/step - accuracy: 0.7666 - loss: 0.6006 - val_accuracy: 0.7944 - val_loss: 0.7726 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9378 - loss: 0.1855\n",
      "Epoch 2: val_accuracy did not improve from 0.79443\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 4s/step - accuracy: 0.9378 - loss: 0.1854 - val_accuracy: 0.7944 - val_loss: 0.6748 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9744 - loss: 0.0846\n",
      "Epoch 3: val_accuracy improved from 0.79443 to 0.88850, saving model to effnet.keras\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 3s/step - accuracy: 0.9744 - loss: 0.0847 - val_accuracy: 0.8885 - val_loss: 0.3874 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9750 - loss: 0.0866\n",
      "Epoch 4: val_accuracy did not improve from 0.88850\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 3s/step - accuracy: 0.9750 - loss: 0.0866 - val_accuracy: 0.8606 - val_loss: 0.4894 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9869 - loss: 0.0392\n",
      "Epoch 5: val_accuracy improved from 0.88850 to 0.89199, saving model to effnet.keras\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 3s/step - accuracy: 0.9869 - loss: 0.0393 - val_accuracy: 0.8920 - val_loss: 0.3564 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9869 - loss: 0.0447\n",
      "Epoch 6: val_accuracy did not improve from 0.89199\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 3s/step - accuracy: 0.9869 - loss: 0.0448 - val_accuracy: 0.7666 - val_loss: 0.8598 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205s/step - accuracy: 0.9819 - loss: 0.0467  \n",
      "Epoch 7: val_accuracy did not improve from 0.89199\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16394s\u001b[0m 205s/step - accuracy: 0.9819 - loss: 0.0466 - val_accuracy: 0.8850 - val_loss: 0.3861 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9884 - loss: 0.0292\n",
      "Epoch 8: val_accuracy improved from 0.89199 to 0.96516, saving model to effnet.keras\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 4s/step - accuracy: 0.9885 - loss: 0.0291 - val_accuracy: 0.9652 - val_loss: 0.1128 - learning_rate: 3.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9964 - loss: 0.0082\n",
      "Epoch 9: val_accuracy improved from 0.96516 to 0.97909, saving model to effnet.keras\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 4s/step - accuracy: 0.9964 - loss: 0.0082 - val_accuracy: 0.9791 - val_loss: 0.0620 - learning_rate: 3.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9965 - loss: 0.0085\n",
      "Epoch 10: val_accuracy did not improve from 0.97909\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 4s/step - accuracy: 0.9965 - loss: 0.0086 - val_accuracy: 0.9686 - val_loss: 0.0942 - learning_rate: 3.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9990 - loss: 0.0040\n",
      "Epoch 11: val_accuracy improved from 0.97909 to 0.98258, saving model to effnet.keras\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 4s/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 0.9826 - val_loss: 0.0684 - learning_rate: 3.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9981 - loss: 0.0052\n",
      "Epoch 12: val_accuracy did not improve from 0.98258\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 4s/step - accuracy: 0.9981 - loss: 0.0052 - val_accuracy: 0.9791 - val_loss: 0.0509 - learning_rate: 3.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9970 - loss: 0.0085\n",
      "Epoch 13: val_accuracy did not improve from 0.98258\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 4s/step - accuracy: 0.9970 - loss: 0.0085 - val_accuracy: 0.9547 - val_loss: 0.1530 - learning_rate: 3.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16s/step - accuracy: 0.9950 - loss: 0.0146 \n",
      "Epoch 14: val_accuracy did not improve from 0.98258\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1295s\u001b[0m 16s/step - accuracy: 0.9950 - loss: 0.0145 - val_accuracy: 0.9826 - val_loss: 0.0827 - learning_rate: 9.0000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9999 - loss: 0.0016\n",
      "Epoch 15: val_accuracy did not improve from 0.98258\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 4s/step - accuracy: 0.9999 - loss: 0.0016 - val_accuracy: 0.9826 - val_loss: 0.0706 - learning_rate: 9.0000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9996 - loss: 0.0029\n",
      "Epoch 16: val_accuracy did not improve from 0.98258\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 4s/step - accuracy: 0.9996 - loss: 0.0029 - val_accuracy: 0.9826 - val_loss: 0.0699 - learning_rate: 2.7000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 17: val_accuracy did not improve from 0.98258\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9826 - val_loss: 0.0716 - learning_rate: 2.7000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9976 - loss: 0.0074\n",
      "Epoch 18: val_accuracy did not improve from 0.98258\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 4s/step - accuracy: 0.9976 - loss: 0.0074 - val_accuracy: 0.9826 - val_loss: 0.0712 - learning_rate: 8.1000e-06\n",
      "Epoch 19/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9997 - loss: 0.0027\n",
      "Epoch 19: val_accuracy did not improve from 0.98258\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 4s/step - accuracy: 0.9997 - loss: 0.0028 - val_accuracy: 0.9826 - val_loss: 0.0716 - learning_rate: 8.1000e-06\n",
      "Epoch 20/50\n",
      "\u001b[1m75/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m22s\u001b[0m 4s/step - accuracy: 0.9993 - loss: 0.0018"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "# Assuming other necessary imports and model setup are already done\n",
    "\n",
    "\n",
    "#Modefied code\n",
    "\n",
    "\n",
    "\n",
    "# TensorBoard callback\n",
    "tensorboard = TensorBoard(log_dir='logs')\n",
    "\n",
    "# ModelCheckpoint callback with .keras extension\n",
    "checkpoint = ModelCheckpoint(\"effnet.keras\", monitor=\"val_accuracy\", save_best_only=True, mode=\"auto\", verbose=1)\n",
    "\n",
    "# ReduceLROnPlateau callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, patience=2, min_delta=0.001, mode='auto', verbose=1)\n",
    "\n",
    "# Assuming model.fit() is called somewhere in your code\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    callbacks=[tensorboard, checkpoint, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b210c9-5989-4f2c-962d-1c89c3c240cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train, y_train, \n",
    "#     validation_split=0.1, epochs=epochs, verbose=1, batch_size=32,\n",
    "#     callbacks=[tensorboard,checkpoint,reduce_lr]\n",
    "# )\n",
    "\n",
    "history = model.fit (\n",
    "    train_gen,\n",
    "    epochs = epochs,\n",
    "    validation_data = val_gen,\n",
    "    validation_steps = len(y_val)//batch_size,\n",
    "    steps_per_epoch = len(y_train)//batch_size,\n",
    "    callbacks = [tensorboard,checkpoint,reduce_lr],\n",
    "    verbose = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c2a19-5b80-4a59-9b85-ae56dc8f0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterwarnings('ignore')\n",
    "\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "range_epochs = [i for i in range(epochs)]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14,7))\n",
    "fig.text(s='Epochs vs. Training and Validation Accuracy/Loss',size=18,fontweight='bold',\n",
    "             fontname='monospace',color=colors_dark[1],y=1,x=0.28,alpha=0.8)\n",
    "\n",
    "sns.despine()\n",
    "ax[0].plot(range_epochs, train_acc, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n",
    "           label = 'Training Accuracy')\n",
    "ax[0].plot(range_epochs, val_acc, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n",
    "           label = 'Validation Accuracy')\n",
    "ax[0].legend(frameon=False)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "\n",
    "sns.despine()\n",
    "ax[1].plot(range_epochs, train_loss, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n",
    "           label ='Training Loss')\n",
    "ax[1].plot(range_epochs, val_loss, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n",
    "           label = 'Validation Loss')\n",
    "ax[1].legend(frameon=False)\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Training & Validation Loss')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62538126-aa44-4b54-9569-b5e25a908f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = model.predict(X_test) # no rescale\n",
    "pred = model.predict(X_test / 255)  # rescale\n",
    "pred = np.argmax(pred, axis=1)\n",
    "y_test_new = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52e5ec1-b7ff-43a7-be03-751a70b19f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_new, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500855fd-bc14-4269-b16f-834f2340103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1,figsize=(14,7))\n",
    "sns.heatmap(confusion_matrix(y_test_new,pred),ax=ax,xticklabels=labels,yticklabels=labels,annot=True,\n",
    "           cmap=colors_green[::-1],alpha=0.7,linewidths=2,linecolor=colors_dark[3])\n",
    "fig.text(s='Heatmap of the Confusion Matrix',size=18,fontweight='bold',\n",
    "             fontname='monospace',color=colors_dark[1],y=0.92,x=0.28,alpha=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e72992f-9ab9-488b-835a-2918d2b3ba49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a00c05b-eca3-4780-80cd-36c5b007090e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
